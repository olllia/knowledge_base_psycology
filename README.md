# База знаний на тему психологии

Этот проект представляет собой пример построения базы знаний в области психологии. Он включает в себя парсинг статей, создание кратких описаний (рефератов) для каждого документа, поиск по базе знаний и визуализацию графа знаний.

## Основные возможности

- **Парсинг статей**: Сбор и обработка текстов статей с сайта [paracels.ru](https://www.paracels.ru).
- **Очистка текста**: Предобработка текстов, включая удаление стоп-слов, лемматизацию и удаление лишних символов.
- **Суммаризация**: Генерация кратких описаний (summary) для каждой статьи с использованием модели [MBart](https://huggingface.co/IlyaGusev/mbart_ru_sum_gazeta).
- **Визуализация графа знаний**: Создание графа, где узлы — это статьи, а связи между ними основаны на схожести их содержимого.
- **Поиск по базе знаний**: Поиск наиболее релевантных статей по заданному запросу с использованием TF-IDF.

## Структура проекта

- `knowledge_base.ipynb`: Jupyter Notebook с кодом проекта.
- `articles_on_psychology_sum.csv`: Файл с обработанными и суммированными данными статей.
- `articles_graph_ex.html`: HTML-файл для визуализации графа знаний.

## Как запустить проект

1. **Клонируйте репозиторий:**
   ```bash
   git clone <ссылка на репозиторий>
   cd <имя папки репозитория>
   ```

2. **Установите зависимости:**
   Убедитесь, что у вас установлен Python 3.10 или выше, и выполните:
   ```bash
   pip install -r requirements.txt
   ```

3. **Запустите Jupyter Notebook:**
   ```bash
   jupyter notebook
   ```
   Откройте файл `knowledge_base.ipynb` и выполните ячейки по порядку.

4. **Просмотрите граф знаний:**
   После выполнения ноутбука файл `articles_graph_ex.html` можно открыть в браузере для визуализации.

5. **Поиск по базе знаний:**
   В последней ячейке ноутбука вы можете ввести запрос, чтобы получить список релевантных статей.

## Используемые библиотеки

- **Парсинг данных:** `beautifulsoup4`, `requests`
- **Обработка текста:** `nltk`, `re`, `pandas`
- **Машинное обучение:** `transformers` (MBart), `scikit-learn`
- **Визуализация:** `pyvis`, `matplotlib`, `wordcloud`
- **Представление графов:** `networkx`

## Пример использования

### 1. Суммаризация текста
Для каждой статьи генерируется краткое описание:
```python
def summarize_text(text):
    input_ids = tokenizer(
        [text],
        max_length=1024,
        padding="max_length",
        truncation=True,
        return_tensors="pt",
    )["input_ids"]

    output_ids = model.generate(
        input_ids=input_ids,
        num_beams=4,
        no_repeat_ngram_size=3,
        min_length=30,
        max_length=150,
        early_stopping=True,
    )[0]

    summary = tokenizer.decode(output_ids, skip_special_tokens=True)
    return summary
```

### 2. Поиск по базе
Введите запрос, чтобы найти релевантные статьи:
```python
query = input("Введите запрос: ")
similar_article_titles = search_articles(query)
print("\nПодходящие статьи:")
for title in similar_article_titles:
    print(title)
```

### 3. Визуализация графа
Граф знаний сохраняется в файл `articles_graph_ex.html`, который можно открыть в браузере.

## Пример графа знаний

Визуализация графа показывает взаимосвязи между статьями, основанные на схожести их текста. Вы можете навести курсор на узел, чтобы увидеть название статьи и её краткое содержание.
